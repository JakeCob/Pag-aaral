{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22577278",
   "metadata": {},
   "source": [
    "- Have a maximum capacity\n",
    "- Store key-value pairs (prompt -> response)\n",
    "- When capacity is reached, evict the least recently used item\n",
    "- Update the \"recently used\" status when a key is accessed (get) or updated (put)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54af5212",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMResponseCache:\n",
    "    cache = {}\n",
    "    recently_used = []\n",
    "\n",
    "    def __init__(self, capacity: int):\n",
    "        self.capacity = capacity\n",
    "\n",
    "    def get(self, prompt: str) -> str | None:\n",
    "        self.recently_used.append(prompt)\n",
    "        return self.cache[prompt]\n",
    "\n",
    "    def put(self, prompt: str, response: str) -> None:\n",
    "        if self.capacity == len(self.cache) and prompt not in self.cache:\n",
    "            self.cache.pop(self.recently_used.pop(0))\n",
    "        self.recently_used.append(prompt)\n",
    "        self.cache[prompt] = response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57e5a485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI stands for Artificial Intelligence...\n",
      "ML is Machine Learning...\n",
      "NLP is Natural Language Processing...\n"
     ]
    }
   ],
   "source": [
    "cache = LLMResponseCache(2)\n",
    "\n",
    "cache.put(\"What is AI?\", \"AI stands for Artificial Intelligence...\")\n",
    "cache.put(\"Define ML\", \"ML is Machine Learning...\")\n",
    "\n",
    "print(cache.get(\"What is AI?\"))  # Output: \"AI stands for Artificial Intelligence...\"\n",
    "\n",
    "cache.put(\"What is NLP?\", \"NLP is Natural Language Processing...\")\n",
    "# Cache is full, \"Define ML\" was least recently used and gets evicted\n",
    "\n",
    "print(cache.get(\"Define ML\"))  # Output: None (evicted)\n",
    "print(cache.get(\"What is NLP?\"))  # Output: \"NLP is Natural Language Processing...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e63c746",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'What is AI?'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m cache\u001b[38;5;241m.\u001b[39mput(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m cache\u001b[38;5;241m.\u001b[39mput(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mcache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mput\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m cache\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt1\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Access prompt1, making it recently used\u001b[39;00m\n\u001b[1;32m      9\u001b[0m cache\u001b[38;5;241m.\u001b[39mput(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt4\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse4\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[18], line 14\u001b[0m, in \u001b[0;36mLLMResponseCache.put\u001b[0;34m(self, prompt, response)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mput\u001b[39m(\u001b[38;5;28mself\u001b[39m, prompt: \u001b[38;5;28mstr\u001b[39m, response: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcapacity \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache) \u001b[38;5;129;01mand\u001b[39;00m prompt \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache:\n\u001b[0;32m---> 14\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecently_used\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecently_used\u001b[38;5;241m.\u001b[39mappend(prompt)\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache[prompt] \u001b[38;5;241m=\u001b[39m response\n",
      "\u001b[0;31mKeyError\u001b[0m: 'What is AI?'"
     ]
    }
   ],
   "source": [
    "cache = LLMResponseCache(3)\n",
    "\n",
    "cache.put(\"prompt1\", \"response1\")\n",
    "cache.put(\"prompt2\", \"response2\")\n",
    "cache.put(\"prompt3\", \"response3\")\n",
    "\n",
    "cache.get(\"prompt1\")  # Access prompt1, making it recently used\n",
    "\n",
    "cache.put(\"prompt4\", \"response4\")\n",
    "# prompt2 is now LRU and gets evicted\n",
    "\n",
    "print(cache.get(\"prompt2\"))  # Output: None\n",
    "print(cache.get(\"prompt1\"))  # Output: \"response1\"\n",
    "print(cache.get(\"prompt3\"))  # Output: \"response3\"\n",
    "print(cache.get(\"prompt4\"))  # Output: \"response4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89eac0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
